{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "745dc79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_stock_price_data, LIST_STOCK\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "07996ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_span = 7\n",
    "history_cols = [f'close_t{i}' for i in range(-time_span+1, 1)]\n",
    "X = np.array(range(0, len(history_cols))).reshape(-1, 1)\n",
    "def compute_slope_history(row):\n",
    "    y = row[history_cols].values.astype(float)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    return model.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7ee6fa09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:44<00:00,  3.65it/s]\n"
     ]
    }
   ],
   "source": [
    "all_preds = []\n",
    "all_truths = []\n",
    "reports = []\n",
    "threshold = 0.03 / time_span # Tăng giảm 3% trong time_span\n",
    "for symbol in tqdm(LIST_STOCK):\n",
    "    df = get_stock_price_data(symbol, with_ground_truth=True)\n",
    "    df.drop(['open', 'high', 'low', 'volume', 'close_t0', 'close_t1', 'close_t2', 'close_t3', 'close_t4', 'close_t5', 'close_t6'], axis=1, inplace=True)\n",
    "    for i in range(-time_span+1, 1):\n",
    "        df[f'close_t{i}'] = df['close'].shift(-i)\n",
    "    df.dropna(inplace=True)\n",
    "    for i in range(0, -time_span, -1):\n",
    "        df[f'close_t{i}'] = df[f'close_t{i}']/df[f'close_t{-time_span+1}']\n",
    "\n",
    "    coef_col_name = f'coef_close_t{-time_span+1}_to_close_t0'\n",
    "    df[coef_col_name] = df.apply(compute_slope_history, axis=1)\n",
    "    df[f'predict'] = np.where(\n",
    "        df[coef_col_name] >= threshold, 'up',\n",
    "        np.where(df[coef_col_name] <= -threshold, 'down', 'sideways')\n",
    "    )\n",
    "    preds = df[\"predict\"].astype(str).str.lower()\n",
    "    truths = df[\"ground_truth\"].astype(str).str.lower()\n",
    "    reports.append((symbol, classification_report(preds, truths, output_dict=True)))\n",
    "    all_preds.extend(preds)\n",
    "    all_truths.extend(truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "498da981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down    0.23146   0.23093   0.23120     16425\n",
      "    sideways    0.60012   0.59876   0.59944     42737\n",
      "          up    0.28258   0.28452   0.28355     19700\n",
      "\n",
      "    accuracy                        0.44365     78862\n",
      "   macro avg    0.37139   0.37140   0.37139     78862\n",
      "weighted avg    0.44401   0.44365   0.44383     78862\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(all_truths, all_preds, digits=5)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3cc89eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_report_to_latex(report_dict):\n",
    "    lines = []\n",
    "    lines.append(r\"\\begin{table}[H]\")\n",
    "    lines.append(r\"\\centering\")\n",
    "    lines.append(r\"\\begin{tabular}{lcccc}\")\n",
    "    lines.append(r\"\\hline\")\n",
    "    lines.append(r\"\\textbf{} & \\textbf{Precision} & \\textbf{Recall} & \\textbf{F1-Score} & \\textbf{Support} \\\\\")\n",
    "    lines.append(r\"\\hline\")\n",
    "    \n",
    "    # Rows for classes\n",
    "    for label in ['down', 'sideways', 'up']:\n",
    "        row = report_dict[label]\n",
    "        line = f\"\\\\textbf{{{label}}} & {row['precision']:.5f} & {row['recall']:.5f} & {row['f1-score']:.5f} & {int(row['support'])} \\\\\\\\\"\n",
    "        lines.append(line)\n",
    "\n",
    "    lines.append(r\"\\hline\")\n",
    "    \n",
    "    # Accuracy\n",
    "    accuracy = report_dict['accuracy']\n",
    "    lines.append(f\"\\\\textbf{{accuracy}} & & & {accuracy:.5f} & {int(report_dict['macro avg']['support'])} \\\\\\\\\")\n",
    "    \n",
    "    # Macro avg\n",
    "    macro = report_dict['macro avg']\n",
    "    lines.append(f\"\\\\textbf{{macro avg}} & {macro['precision']:.5f} & {macro['recall']:.5f} & {macro['f1-score']:.5f} & {int(macro['support'])} \\\\\\\\\")\n",
    "    \n",
    "    # Weighted avg\n",
    "    weighted = report_dict['weighted avg']\n",
    "    lines.append(f\"\\\\textbf{{weighted avg}} & {weighted['precision']:.5f} & {weighted['recall']:.5f} & {weighted['f1-score']:.5f} & {int(weighted['support'])} \\\\\\\\\")\n",
    "    \n",
    "    lines.append(r\"\\hline\")\n",
    "    lines.append(r\"\\end{tabular}\")\n",
    "    lines.append(r\"\\caption{Classification Report}\")\n",
    "    lines.append(r\"\\end{table}\")\n",
    "    \n",
    "    latex_code = \"\\n\".join(lines)\n",
    "    print(latex_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f231d69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[H]\n",
      "\\centering\n",
      "\\begin{tabular}{lcccc}\n",
      "\\hline\n",
      "\\textbf{} & \\textbf{Precision} & \\textbf{Recall} & \\textbf{F1-Score} & \\textbf{Support} \\\\\n",
      "\\hline\n",
      "\\textbf{down} & 0.23146 & 0.23093 & 0.23120 & 16425 \\\\\n",
      "\\textbf{sideways} & 0.60012 & 0.59876 & 0.59944 & 42737 \\\\\n",
      "\\textbf{up} & 0.28258 & 0.28452 & 0.28355 & 19700 \\\\\n",
      "\\hline\n",
      "\\textbf{accuracy} & & & 0.44365 & 78862 \\\\\n",
      "\\textbf{macro avg} & 0.37139 & 0.37140 & 0.37139 & 78862 \\\\\n",
      "\\textbf{weighted avg} & 0.44401 & 0.44365 & 0.44383 & 78862 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\caption{Classification Report}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "classification_report_to_latex(classification_report(all_truths, all_preds, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "391babfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "reports.sort(key=lambda x: x[1]['weighted avg']['f1-score'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fd31bc2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THD (0.92900), SSH (0.89481), DSN (0.85326), ODE (0.80670), KDC (0.79055), SMB (0.78645), VSH (0.68952), EID (0.67432), VJC (0.64413), VNS (0.64403), "
     ]
    }
   ],
   "source": [
    "for x in reports[:10]:\n",
    "    print(f\"{x[0]} ({x[1]['weighted avg']['f1-score']:.5f})\", end=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3ef8acb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MWG (0.33029), SKG (0.32258), VIF (0.31032), VGI (0.31017), MSR (0.30619), NKG (0.30144), PLC (0.30095), ELC (0.29997), BCG (0.29723), SBD (0.29518), "
     ]
    }
   ],
   "source": [
    "for x in reports[-10:]:\n",
    "    print(f\"{x[0]} ({x[1]['weighted avg']['f1-score']:.5f})\", end=', ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
