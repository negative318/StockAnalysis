{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f084ce3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_stock_price_data\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90388275",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_span = 7\n",
    "lag_cols = [f'close_t{i}' for i in range(-time_span, 1)]\n",
    "X = np.array(range(1, len(lag_cols)+1)).reshape(-1, 1)\n",
    "def compute_slope_history(row):\n",
    "    y = row[lag_cols].values.astype(float)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    return model.coef_[0]\n",
    "\n",
    "future_cols = [f'close_t{i}' for i in range(0, time_span+1)]\n",
    "X2 = np.array(range(1, len(future_cols)+1)).reshape(-1, 1)\n",
    "def compute_slope_future(row):\n",
    "    y = row[future_cols].values.astype(float)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X2, y)\n",
    "    return model.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e15d3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = \"VCB\"\n",
    "threshold = 0.05\n",
    "df = get_stock_price_data(symbol)\n",
    "df.drop(['open', 'high', 'low', 'volume'], axis=1, inplace=True)\n",
    "\n",
    "for i in range(-time_span, time_span+1):\n",
    "    df[f'close_t{i}'] = df['close'].shift(-i)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "coef_col_name = f'coef_close_t{-time_span}_to_close'\n",
    "df[coef_col_name] = df.apply(compute_slope_history, axis=1)\n",
    "df[f'predict'] = np.where(\n",
    "    df[coef_col_name] >= threshold, 'up',\n",
    "    np.where(df[coef_col_name] <= -threshold, 'down', 'sideways')\n",
    ")\n",
    "\n",
    "coef_col_name = f'coef_close_to_close_t{time_span}'\n",
    "df[coef_col_name] = df.apply(compute_slope_future, axis=1)\n",
    "df[f'ground_truth'] = np.where(\n",
    "    df[coef_col_name] >= threshold, 'up',\n",
    "    np.where(df[coef_col_name] <= -threshold, 'down', 'sideways')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ead8cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>close</th>\n",
       "      <th>close_t-7</th>\n",
       "      <th>close_t-6</th>\n",
       "      <th>close_t-5</th>\n",
       "      <th>close_t-4</th>\n",
       "      <th>close_t-3</th>\n",
       "      <th>close_t-2</th>\n",
       "      <th>close_t-1</th>\n",
       "      <th>close_t0</th>\n",
       "      <th>...</th>\n",
       "      <th>close_t2</th>\n",
       "      <th>close_t3</th>\n",
       "      <th>close_t4</th>\n",
       "      <th>close_t5</th>\n",
       "      <th>close_t6</th>\n",
       "      <th>close_t7</th>\n",
       "      <th>coef_close_t-7_to_close</th>\n",
       "      <th>predict</th>\n",
       "      <th>coef_close_to_close_t7</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-04-10</td>\n",
       "      <td>50.41</td>\n",
       "      <td>52.50</td>\n",
       "      <td>51.77</td>\n",
       "      <td>52.56</td>\n",
       "      <td>52.10</td>\n",
       "      <td>52.16</td>\n",
       "      <td>51.65</td>\n",
       "      <td>50.97</td>\n",
       "      <td>50.41</td>\n",
       "      <td>...</td>\n",
       "      <td>50.01</td>\n",
       "      <td>49.95</td>\n",
       "      <td>50.07</td>\n",
       "      <td>50.07</td>\n",
       "      <td>49.84</td>\n",
       "      <td>50.12</td>\n",
       "      <td>-0.253571</td>\n",
       "      <td>down</td>\n",
       "      <td>-0.027143</td>\n",
       "      <td>sideways</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-04-11</td>\n",
       "      <td>49.95</td>\n",
       "      <td>51.77</td>\n",
       "      <td>52.56</td>\n",
       "      <td>52.10</td>\n",
       "      <td>52.16</td>\n",
       "      <td>51.65</td>\n",
       "      <td>50.97</td>\n",
       "      <td>50.41</td>\n",
       "      <td>49.95</td>\n",
       "      <td>...</td>\n",
       "      <td>49.95</td>\n",
       "      <td>50.07</td>\n",
       "      <td>50.07</td>\n",
       "      <td>49.84</td>\n",
       "      <td>50.12</td>\n",
       "      <td>50.01</td>\n",
       "      <td>-0.326071</td>\n",
       "      <td>down</td>\n",
       "      <td>0.007619</td>\n",
       "      <td>sideways</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-04-12</td>\n",
       "      <td>50.01</td>\n",
       "      <td>52.56</td>\n",
       "      <td>52.10</td>\n",
       "      <td>52.16</td>\n",
       "      <td>51.65</td>\n",
       "      <td>50.97</td>\n",
       "      <td>50.41</td>\n",
       "      <td>49.95</td>\n",
       "      <td>50.01</td>\n",
       "      <td>...</td>\n",
       "      <td>50.07</td>\n",
       "      <td>50.07</td>\n",
       "      <td>49.84</td>\n",
       "      <td>50.12</td>\n",
       "      <td>50.01</td>\n",
       "      <td>49.56</td>\n",
       "      <td>-0.411071</td>\n",
       "      <td>down</td>\n",
       "      <td>-0.034881</td>\n",
       "      <td>sideways</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-04-13</td>\n",
       "      <td>49.95</td>\n",
       "      <td>52.10</td>\n",
       "      <td>52.16</td>\n",
       "      <td>51.65</td>\n",
       "      <td>50.97</td>\n",
       "      <td>50.41</td>\n",
       "      <td>49.95</td>\n",
       "      <td>50.01</td>\n",
       "      <td>49.95</td>\n",
       "      <td>...</td>\n",
       "      <td>50.07</td>\n",
       "      <td>49.84</td>\n",
       "      <td>50.12</td>\n",
       "      <td>50.01</td>\n",
       "      <td>49.56</td>\n",
       "      <td>49.78</td>\n",
       "      <td>-0.374524</td>\n",
       "      <td>down</td>\n",
       "      <td>-0.043333</td>\n",
       "      <td>sideways</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-04-14</td>\n",
       "      <td>50.07</td>\n",
       "      <td>52.16</td>\n",
       "      <td>51.65</td>\n",
       "      <td>50.97</td>\n",
       "      <td>50.41</td>\n",
       "      <td>49.95</td>\n",
       "      <td>50.01</td>\n",
       "      <td>49.95</td>\n",
       "      <td>50.07</td>\n",
       "      <td>...</td>\n",
       "      <td>49.84</td>\n",
       "      <td>50.12</td>\n",
       "      <td>50.01</td>\n",
       "      <td>49.56</td>\n",
       "      <td>49.78</td>\n",
       "      <td>50.01</td>\n",
       "      <td>-0.315119</td>\n",
       "      <td>down</td>\n",
       "      <td>-0.033571</td>\n",
       "      <td>sideways</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>2025-03-13</td>\n",
       "      <td>65.50</td>\n",
       "      <td>62.21</td>\n",
       "      <td>62.21</td>\n",
       "      <td>62.54</td>\n",
       "      <td>63.61</td>\n",
       "      <td>64.75</td>\n",
       "      <td>64.75</td>\n",
       "      <td>66.70</td>\n",
       "      <td>65.50</td>\n",
       "      <td>...</td>\n",
       "      <td>67.30</td>\n",
       "      <td>66.80</td>\n",
       "      <td>66.50</td>\n",
       "      <td>66.80</td>\n",
       "      <td>66.00</td>\n",
       "      <td>66.50</td>\n",
       "      <td>0.633929</td>\n",
       "      <td>up</td>\n",
       "      <td>0.061905</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>2025-03-14</td>\n",
       "      <td>66.00</td>\n",
       "      <td>62.21</td>\n",
       "      <td>62.54</td>\n",
       "      <td>63.61</td>\n",
       "      <td>64.75</td>\n",
       "      <td>64.75</td>\n",
       "      <td>66.70</td>\n",
       "      <td>65.50</td>\n",
       "      <td>66.00</td>\n",
       "      <td>...</td>\n",
       "      <td>66.80</td>\n",
       "      <td>66.50</td>\n",
       "      <td>66.80</td>\n",
       "      <td>66.00</td>\n",
       "      <td>66.50</td>\n",
       "      <td>66.20</td>\n",
       "      <td>0.602381</td>\n",
       "      <td>up</td>\n",
       "      <td>-0.055952</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>2025-03-17</td>\n",
       "      <td>67.30</td>\n",
       "      <td>62.54</td>\n",
       "      <td>63.61</td>\n",
       "      <td>64.75</td>\n",
       "      <td>64.75</td>\n",
       "      <td>66.70</td>\n",
       "      <td>65.50</td>\n",
       "      <td>66.00</td>\n",
       "      <td>67.30</td>\n",
       "      <td>...</td>\n",
       "      <td>66.50</td>\n",
       "      <td>66.80</td>\n",
       "      <td>66.00</td>\n",
       "      <td>66.50</td>\n",
       "      <td>66.20</td>\n",
       "      <td>65.80</td>\n",
       "      <td>0.588929</td>\n",
       "      <td>up</td>\n",
       "      <td>-0.170238</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>2025-03-18</td>\n",
       "      <td>66.80</td>\n",
       "      <td>63.61</td>\n",
       "      <td>64.75</td>\n",
       "      <td>64.75</td>\n",
       "      <td>66.70</td>\n",
       "      <td>65.50</td>\n",
       "      <td>66.00</td>\n",
       "      <td>67.30</td>\n",
       "      <td>66.80</td>\n",
       "      <td>...</td>\n",
       "      <td>66.80</td>\n",
       "      <td>66.00</td>\n",
       "      <td>66.50</td>\n",
       "      <td>66.20</td>\n",
       "      <td>65.80</td>\n",
       "      <td>65.50</td>\n",
       "      <td>0.447976</td>\n",
       "      <td>up</td>\n",
       "      <td>-0.165476</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>66.50</td>\n",
       "      <td>64.75</td>\n",
       "      <td>64.75</td>\n",
       "      <td>66.70</td>\n",
       "      <td>65.50</td>\n",
       "      <td>66.00</td>\n",
       "      <td>67.30</td>\n",
       "      <td>66.80</td>\n",
       "      <td>66.50</td>\n",
       "      <td>...</td>\n",
       "      <td>66.00</td>\n",
       "      <td>66.50</td>\n",
       "      <td>66.20</td>\n",
       "      <td>65.80</td>\n",
       "      <td>65.50</td>\n",
       "      <td>64.80</td>\n",
       "      <td>0.295238</td>\n",
       "      <td>up</td>\n",
       "      <td>-0.229762</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>485 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           time  close  close_t-7  close_t-6  close_t-5  close_t-4  close_t-3  \\\n",
       "7    2023-04-10  50.41      52.50      51.77      52.56      52.10      52.16   \n",
       "8    2023-04-11  49.95      51.77      52.56      52.10      52.16      51.65   \n",
       "9    2023-04-12  50.01      52.56      52.10      52.16      51.65      50.97   \n",
       "10   2023-04-13  49.95      52.10      52.16      51.65      50.97      50.41   \n",
       "11   2023-04-14  50.07      52.16      51.65      50.97      50.41      49.95   \n",
       "..          ...    ...        ...        ...        ...        ...        ...   \n",
       "487  2025-03-13  65.50      62.21      62.21      62.54      63.61      64.75   \n",
       "488  2025-03-14  66.00      62.21      62.54      63.61      64.75      64.75   \n",
       "489  2025-03-17  67.30      62.54      63.61      64.75      64.75      66.70   \n",
       "490  2025-03-18  66.80      63.61      64.75      64.75      66.70      65.50   \n",
       "491  2025-03-19  66.50      64.75      64.75      66.70      65.50      66.00   \n",
       "\n",
       "     close_t-2  close_t-1  close_t0  ...  close_t2  close_t3  close_t4  \\\n",
       "7        51.65      50.97     50.41  ...     50.01     49.95     50.07   \n",
       "8        50.97      50.41     49.95  ...     49.95     50.07     50.07   \n",
       "9        50.41      49.95     50.01  ...     50.07     50.07     49.84   \n",
       "10       49.95      50.01     49.95  ...     50.07     49.84     50.12   \n",
       "11       50.01      49.95     50.07  ...     49.84     50.12     50.01   \n",
       "..         ...        ...       ...  ...       ...       ...       ...   \n",
       "487      64.75      66.70     65.50  ...     67.30     66.80     66.50   \n",
       "488      66.70      65.50     66.00  ...     66.80     66.50     66.80   \n",
       "489      65.50      66.00     67.30  ...     66.50     66.80     66.00   \n",
       "490      66.00      67.30     66.80  ...     66.80     66.00     66.50   \n",
       "491      67.30      66.80     66.50  ...     66.00     66.50     66.20   \n",
       "\n",
       "     close_t5  close_t6  close_t7  coef_close_t-7_to_close  predict  \\\n",
       "7       50.07     49.84     50.12                -0.253571     down   \n",
       "8       49.84     50.12     50.01                -0.326071     down   \n",
       "9       50.12     50.01     49.56                -0.411071     down   \n",
       "10      50.01     49.56     49.78                -0.374524     down   \n",
       "11      49.56     49.78     50.01                -0.315119     down   \n",
       "..        ...       ...       ...                      ...      ...   \n",
       "487     66.80     66.00     66.50                 0.633929       up   \n",
       "488     66.00     66.50     66.20                 0.602381       up   \n",
       "489     66.50     66.20     65.80                 0.588929       up   \n",
       "490     66.20     65.80     65.50                 0.447976       up   \n",
       "491     65.80     65.50     64.80                 0.295238       up   \n",
       "\n",
       "    coef_close_to_close_t7  ground_truth  \n",
       "7                -0.027143      sideways  \n",
       "8                 0.007619      sideways  \n",
       "9                -0.034881      sideways  \n",
       "10               -0.043333      sideways  \n",
       "11               -0.033571      sideways  \n",
       "..                     ...           ...  \n",
       "487               0.061905            up  \n",
       "488              -0.055952          down  \n",
       "489              -0.170238          down  \n",
       "490              -0.165476          down  \n",
       "491              -0.229762          down  \n",
       "\n",
       "[485 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24890b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['close_t-7', 'close_t-6', 'close_t-5', 'close_t-4', 'close_t-3', 'close_t-2', 'close_t-1', 'close_t0']].values\n",
    "for i in range(len(X)):\n",
    "    X[i] = X[i]/X[i][0]\n",
    "y_label = df['ground_truth'].values\n",
    "y = []\n",
    "for s in y_label:\n",
    "    if s == 'sideways':\n",
    "        y.append([0.0, 1.0, 0.0])\n",
    "    elif s == 'up':\n",
    "        y.append([1.0, 0.0, 0.0])\n",
    "    elif s == 'down':\n",
    "        y.append([0.0, 0.0, 1.0])\n",
    "y = np.array(y)\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6688ef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X).float()\n",
    "        self.y = torch.tensor(y).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_dataset = TimeSeriesDataset(X_train, y_train)\n",
    "test_dataset = TimeSeriesDataset(X_test, y_test)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6904bdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size=8, output_size=3):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        hidden_size = 128\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_size, output_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "08967d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = SimpleNN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "376c3266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "SimpleNN                                 --\n",
       "├─Sequential: 1-1                        --\n",
       "│    └─Linear: 2-1                       1,152\n",
       "│    └─GELU: 2-2                         --\n",
       "│    └─Linear: 2-3                       16,512\n",
       "│    └─GELU: 2-4                         --\n",
       "│    └─Linear: 2-5                       16,512\n",
       "│    └─GELU: 2-6                         --\n",
       "│    └─Linear: 2-7                       387\n",
       "=================================================================\n",
       "Total params: 34,563\n",
       "Trainable params: 34,563\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f0964187",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:25<00:00, 39.12it/s]\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    model.train()\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a8f39b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1000, Train Loss: 13.6829, Train Acc: 0.4253\n",
      "Epoch: 1000, Test Loss: 4.0873, Test Acc: 0.3711\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss = 0\n",
    "correct_test = 0\n",
    "train_loss = 0\n",
    "correct_train = 0\n",
    "label_indices_list = []\n",
    "pred_indices_list = []\n",
    "with torch.inference_mode():\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        train_loss += loss.item()\n",
    "        label_indices = torch.argmax(targets, dim=1)\n",
    "        pred_indices = torch.argmax(outputs, dim=1)\n",
    "        correct_train += (pred_indices == label_indices).int().sum()\n",
    "\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        test_loss += loss.item()\n",
    "        label_indices = torch.argmax(targets, dim=1)\n",
    "        pred_indices = torch.argmax(outputs, dim=1)\n",
    "        label_indices_list.append(label_indices)\n",
    "        pred_indices_list.append(pred_indices)\n",
    "        correct_test += (pred_indices == label_indices).int().sum()\n",
    "\n",
    "    \n",
    "\n",
    "print(f'Epoch: {epoch + 1:02d}, Train Loss: {train_loss:.4f}, Train Acc: {correct_train / len(train_loader.dataset):.4f}')\n",
    "print(f'Epoch: {epoch + 1:02d}, Test Loss: {test_loss:.4f}, Test Acc: {correct_test / len(test_loader.dataset):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e2c9ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = []\n",
    "for x in label_indices_list:\n",
    "    for y in x:\n",
    "        if y.item() == 0:\n",
    "            label_list.append('up')\n",
    "        elif y.item() == 1:\n",
    "            label_list.append('sideways')\n",
    "        elif y.item() == 2:\n",
    "            label_list.append('down')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3351c1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = []\n",
    "for x in pred_indices_list:\n",
    "    for y in x:\n",
    "        if y.item() == 0:\n",
    "            pred_list.append('up')\n",
    "        elif y.item() == 1:\n",
    "            pred_list.append('sideways')\n",
    "        elif y.item() == 2:\n",
    "            pred_list.append('down')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1c45ca46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down       0.35      0.85      0.49        34\n",
      "    sideways       0.00      0.00      0.00        25\n",
      "          up       0.54      0.18      0.27        38\n",
      "\n",
      "    accuracy                           0.37        97\n",
      "   macro avg       0.29      0.35      0.26        97\n",
      "weighted avg       0.33      0.37      0.28        97\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\minhh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\minhh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\minhh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(label_list, pred_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
